{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Python free-threading guide","text":"<p>Free-threaded CPython is coming!  </p> <p>After the acceptance by the Python Steering Council of, and the gradual rollout strategy for, PEP 703 - Making the Global Interpreter Lock Optional in CPython, a lot of work is happening both in CPython itself and across the Python ecosystem.</p> <p>This website aims to serve as a centralized resource both for Python package maintainers and end users interested in supporting or experimenting with free-threaded Python. We are tracking the compatibility of a number of packages that include native code, you can take a look at our progress here:</p> <ul> <li>Compatibility Status Tracking</li> </ul> <p>This website also provide documentation and guidance for setting up a free-threaded Python development environment and getting code working under the free-threaded build.</p>"},{"location":"#installing-and-running-free-threaded-python","title":"Installing and Running Free-threaded Python","text":"<p>The following sections describe how to install free-threaded Python and how to run with the GIL disabled and verify that is the case.</p> <ul> <li>Installing Free-Threaded Python</li> <li>Running Python with the GIL Disabled</li> </ul>"},{"location":"#updating-code-to-run-on-free-threaded-python","title":"Updating code to run on free-threaded Python","text":"<p>If you are interested in updating your code to work on free-threaded Python, what you need to do depends on your needs and goals. Please select the option that best describes you:</p> I am writing a Python script or application that uses Python libraries I don't maintain <p>You should start experimenting with free-threaded Python once the libraries you depend on advertise support for free-threading. See the tracking table for more details about the status of free-threaded support in Python libraries.</p> <p>If your dependencies advertise free-threaded support, good news! If you do not use the <code>threading</code> module and do not plan to, then you're done and you can feel safe declaring support for running your project on the free-threaded build.</p> <p>If you would like to use the <code>threading</code> module to improve the performance of your project, you should read the documentation of your dependencies and learn about their thread safety guarantees. This is particularly true of libraries that expose mutable objects, doubly so if you want to mutate a shared object from many threads.</p> <p>Pure Python code can exhibit thread safety issues, so you may also want to look at the first section of the porting guide, particularly on the thread safety of pure Python code:</p> <ul> <li>Porting Python Packages to Support Free-Threading</li> </ul> I maintain a pure Python app or tool written in pure Python with no public Python API <p>You should start experimenting with free-threaded Python once the libraries you depend on advertise support for free-threading. See the tracking table for more details about the status of free-threaded support in Python libraries.</p> <p>If your dependencies advertise free-threaded support, good news! If you do not use the <code>threading</code> module and do not plan to, then you're done and you can feel safe declaring support for running your project on the free-threaded build.</p> <p>If you make use of the <code>threading</code> module internally and already have multithreaded tests, consider experimenting with your existing tests with a very short thread switch interval. This can elicit thread safety issues on the GIL-enabled build. If you do not use <code>threading</code> or thread pools internally your tool or app should behave identically under free-threading.</p> <p>If you would like to use the <code>threading</code> module to improve the performance of your project, you should read the documentation of your dependencies and learn about their thread safety guarantees. This is particularly true of libraries that expose mutable objects, doubly so if you want to mutate a shared object from many threads.</p> <p>Pure Python code can exhibit thread safety issues, so you may also want to look at the first section of the porting guide, particularly on the thread safety of pure Python code:</p> <ul> <li>Porting Python Packages to Support Free-Threading</li> </ul> I maintain a pure Python package with a public Python API <p>Free-threading is implemented in CPython such that pure Python code is thread-safe, at least to the same extent as it is with the GIL enabled today. We use \"thread-safe\" here to mean that CPython should not crash running multithreaded pure Python code, not necessarily that a multithreaded program will always produce deterministic results, even if the GIL-enabled build is deterministic. It is up to the author of a program, application, or library to ensure safe multithreaded usage when using the library in a supported manner.</p> <p>There are a few ways you can create thread safety issues in your own code. The most common ones are: using global state for configuration or other purposes, implementing a cache with a dict or other variable not meant for that purpose, or using functionality of a dependency that itself isn't thread-safe. You should also think about whether you would like to support multithreaded use of any mutable data structures exposed by your package. If your package does none of those things, you are very likely ready for free-threading already.</p> <p>What gets trickier is testing whether your package is thread-safe. For that you'll need multi-threaded tests, and that can be more involved - see our guide to adding multithreaded test coverage to Python packages.</p> <ul> <li>Porting Python Packages to Support Free-Threading</li> <li>Improving Multithreaded Test Coverage</li> </ul> I maintain a Python package with compiled extension modules <p>As usual with extensions, dealing with native code will take some work but we hope that this guide will provide you with a toolkit to get things working.</p> <p>We suggest reading through the the full porting guide, including the final section that focuses on considerations for native code.</p> <ul> <li>Porting Python Packages to Support Free-Threading</li> <li>Improving Multithreaded Test Coverage</li> <li>Updating Native Extensions to Support Free-Threading</li> </ul>"},{"location":"#advanced-topics-for-package-maintainers","title":"Advanced topics for package maintainers","text":"<ul> <li>Setting up Continuous Integration</li> <li>Debugging Thread Safety Issues</li> </ul>"},{"location":"#further-reading","title":"Further reading","text":"<p>We've collected more resources on free-threaded Python and multithreaded programming here:</p> <ul> <li>More Resources</li> </ul>"},{"location":"#about-this-site","title":"About this site","text":"<p>Any contributions are very much welcome - please open issues or pull requests on this repo for anything that seems in scope for this site or for tracking issues related to support for free-threaded Python across the ecosystem.</p> <p>This site is maintained primarily by Quansight Labs, where a team is working together with the Python runtime team at Meta and stakeholders across the ecosystem to jumpstart work on converting the libraries that make up the scientific Python and AI/ML stacks to work with the free-threaded build of CPython 3.13. Additionally, that effort will look at libraries like PyO3 that are needed to interface with CPython from other languages.</p>"},{"location":"ci/","title":"Setting up CI","text":""},{"location":"ci/#ci-setup-via-setup-python","title":"CI setup via <code>setup-python</code>","text":"<p>The easiest way to get a free-threaded Python build on a CI runner is with the <code>setup-python</code> Github Action:</p> <pre><code>jobs:\n  free-threaded:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@...\n      - uses: actions/setup-python@...\n        with:\n          python-version: 3.13t\n</code></pre>"},{"location":"ci/#ci-setup-via-setup-uv","title":"CI setup via <code>setup-uv</code>","text":"<p>An alternative to <code>setup-python</code> is to use <code>setup-uv</code> Github Action:</p> <pre><code>jobs:\n  free-threaded:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@...\n      - uses: astral-sh/setup-uv@...\n        with:\n          python-version: 3.13t\n</code></pre> <p>You should replace the ellipses with versions for the actions.</p>"},{"location":"ci/#windows-ci-setup-via-custom-powershell","title":"Windows CI setup via custom PowerShell","text":"<p>For installing a free-threaded build of Python on a Windows CI runner (<code>runs-on: windows-latest</code>), you can download and install directly from https://www.python.org/ftp/python/ as shown in the following PowerShell snippet (noting that the free-threaded binary is named <code>python{version}t.exe</code>, where the \"t\" is for free-\"t\"hreaded). For more tips see the docs on silent installation and options on Windows.</p> <pre><code>jobs:\n  free-threaded:\n    runs-on: windows-latest\n    steps:\n      - uses: actions/checkout@...\n      - name: custom python install script\n        shell: pwsh\n        run: |\n          $pythonInstallerUrl = 'https://www.nuget.org/api/v2/package/python-freethreaded/3.13.1'\n          Invoke-WebRequest $pythonInstallerUrl -OutFile 'python-freethreaded.3.13.1.nupkg'\n          Install-Package python-freethreaded -Scope CurrentUser -Source $pwd\n          $python_dir = (Get-Item((Get-Package -Name python-freethreaded).Source)).DirectoryName\n          $env:path = $python_dir + \"\\tools;\" + $python_dir + \"\\tools\\Scripts;\" + $env:Path\n</code></pre>"},{"location":"ci/#building-free-threaded-wheels-with-cibuildwheel","title":"Building free-threaded wheels with cibuildwheel","text":"<p>cibuildwheel has support for building free-threaded wheels on all platforms. If your project releases nightly wheels, we suggest configuring <code>cibuildwheel</code> to build nightly free-threaded wheels.</p> <p>If your project depends on Cython or the NumPy C API, you will need to install a Cython nightly wheel in the build, as the newest stable release of Cython cannot generate code that will compile under the free-threaded build. Cython 3.1.0 and NumPy 2.1.0 will be or are the first stable releases to support free-threaded python. See the project tracker for more detailed information about projects you may depend on.</p> <p>You can install nightly wheels for both Cython and NumPy using the following install command:</p> <pre><code>pip install -i https://pypi.anaconda.org/scientific-python-nightly-wheels/simple cython numpy\n</code></pre> <p>To ensure wheels are built correctly under cibuildwheel, you will need to specify the following variables in the environment for the cibuildwheel action:</p> <pre><code>  - name: Build wheels\n    uses: pypa/cibuildwheel@...\n    env:\n      CIBW_PRERELEASE_PYTHONS: true\n      CIBW_FREE_THREADED_SUPPORT: true\n      CIBW_BUILD: cp313t-${{ matrix.buildplat }}\n      # TODO:\n      # remove when a released cython can build free-threaded extensions\n      CIBW_BUILD_FRONTEND: 'pip; args: --no-build-isolation'\n</code></pre> <p>As above, replace the ellipses with a <code>cibuildwheel</code> version.</p> <p>If for some reason disabling build isolation is unworkable, you can also tell pip about the nightly wheel index and it will use it in an isolated build. To do this, set:</p> <pre><code>CIBW_BUILD_FRONTEND: 'pip; args: --pre --extra-index-url \"https://pypi.anaconda.org/scientific-python-nightly-wheels/simple\"'\n</code></pre> <p>Many projects use <code>build</code> instead of <code>pip</code> for the build frontend. See the cibuildwheel docs for more information about how to pass arguments to <code>build</code> and <code>pip</code>. See this comment on the <code>build</code> issue tracker if you need to use <code>build</code> and cannot disable build isolation.</p> <p>Note that nightly wheels may not be available on all platforms yet. Windows wheels, in particular, are not currently available for NumPy or projects that depend on NumPy (e.g., SciPy).</p> <p>You will also likely need to manually pass <code>-Xgil=0</code> or set <code>PYTHON_GIL=0</code> in your shell environment while running tests to ensure the GIL is actually disabled during tests, at least until you can register that your extension modules support disabling the GIL via <code>Py_mod_gil</code> and all of your runtime test dependencies do the same. See the porting guide for more information about declaring support for free-threaded python in your extension.</p> <p>Info</p> <p>If a dependency of your package does not support free-threading or has not yet done a release which includes <code>cp313t</code> wheels, this can be tricky to work around because an environment marker for free-threading does not exist (see this Discourse thread). Hence it is not possible to special-case free-threading with static metadata in <code>pyproject.toml</code>. It's fine to still upload <code>cp313t</code> wheels for your package to PyPI; the user may then be responsible for getting the dependency installed (e.g., from a nightly wheel or building the dependency's <code>main</code> branch from source) if the last release of the dependency doesn't cleanly build from source or doesn't work under free-threading.</p>"},{"location":"debugging/","title":"Debugging thread safety issues","text":"<p>Until now, the GIL has allowed developers to ignore C safety issues when writing parallel programs, since the GIL ensured that all thread execution was serialized, allowing for simultaneous access to Python objects and state defined in the interpreter.</p> <p>The new free-threaded model ensures that Python code access originating from other Python code frames is safe and is guaranteed to not produce any major interpreter crash, as opposed to unrestricted C code access, which can present any of the common C thread-safety issues.</p> <p>Usually, concurrency issues arise when two or more threads try to modify the same value in memory. In Python, this commonly occurs when a class or function defines native shared state, either via an attribute or a variable that can be modified from native code in each thread execution scope.</p> <p>The most common issues related to concurrency in the context of free-threaded CPython extensions are either dirty reads/writes to global/shared C state, unexpected behavior due to simultaneous access to C calls that are not thread-safe, and finally, major runtime crashes due to memory allocation issues and forbidden pointer lookups. While the first case depends on the actual implementation of the algorithm/routine and may produce unintended results, it would not cause a fatal crash of the interpreter, as opposed to the last two cases.</p> <p>In order to discover, handle and debug concurrency issues at large, there are several strategies, which we will summarize next.</p>"},{"location":"debugging/#pytest-plugins-to-discover-concurrency-issues","title":"pytest plugins to discover concurrency issues","text":"<p>As parallel testing has become a critical component to ensure compatibility with free-threaded CPython, several community-led pytest plugins have been implemented that attempt to smoke out issues by running all tests in a test suite in a concurrent manner:</p> <ul> <li>pytest-run-parallel</li> <li>pytest-freethreaded</li> </ul> <p>The advantage of using a pytest plugin as opposed to manually using the <code>threading</code> and/or <code>concurrent.futures</code> modules mainly resides in their ability to integrate with the ecosystem constructs like markers, fixtures, skip and failure flags. For more information regarding the usage of these libraries please refer to the documentation of each project.</p>"},{"location":"debugging/#repeated-test-execution","title":"Repeated test execution","text":"<p>Given the non-deterministic nature of parallel execution, tests for code that has a concurrency issue may still pass most of the time. In order to more reliably reproduce a test failure under concurrency, we recommend using pytest-repeat, which enables the <code>--count</code> flag in the <code>pytest</code> command:</p> <pre><code># Setting PYTHON_GIL=0 ensures that the GIL is effectively disabled.\nPYTHON_GIL=0 pytest -x -v --count=100 test_concurrent.py\n</code></pre> <p>We advise to set <code>count</code> to <code>100</code> (or even larger if needed), in order to ensure at least one concurrent clash event.</p>"},{"location":"debugging/#writing-explicitly-concurrent-test-cases","title":"Writing explicitly concurrent test cases","text":"<p>It may be desirable to have tests using, e.g., <code>threading</code> or <code>concurrent.futures</code> in your test suite in order to prevent adding additional test dependencies or to test a particular subset of tests for concurrency issues by default. The stdlib <code>threading</code> module defines several low-level parallel primitives that can be used to test for concurrency, while the <code>concurrent.futures</code> module provides higher-level constructs.</p> <p>For example, consider a method <code>MyClass.call_unsafe</code> that has been flagged as having concurrency issues since it mutates attributes of a shared object that is accessed by multiple threads. We can write a test for it using either <code>threading</code> or <code>concurrent.futures</code> primitives:</p> Example using threading: <pre><code>import threading\n\n# Library to test\nfrom mylib import MyClass\n\n\ndef test_call_unsafe_concurrent_threading():\n    # Defines a thread barrier that will be spawned before parallel execution\n    # this increases the probability of concurrent access clashes.\n    n_threads = 10\n    barrier = threading.Barrier(n_threads)\n\n    # This object will be shared by all the threads.\n    cls_instance = MyClass(...)\n\n    results = []\n\n    def closure():\n        # Ensure that all threads reach this point before concurrent execution.\n        barrier.wait()\n        r = cls_instance.call_unsafe()\n        results.append(r)\n\n    # Spawn n threads that call call_unsafe concurrently.\n    workers = []\n    for _ in range(0, n_threads):\n        workers.append(threading.Thread(target=closure))\n\n    for worker in workers:\n        worker.start()\n\n    for worker in workers:\n        worker.join()\n\n    # Do something about the results\n    assert check_results(results)\n</code></pre> Example using concurrent.futures: <pre><code>import threading\nfrom concurrent.futures import ThreadPoolExecutor\n\n# Library to test\nfrom mylib import MyClass\n\n\ndef test_call_unsafe_concurrent_pool():\n    # Defines a thread barrier that will be spawned before parallel execution\n    # this increases the probability of concurrent access clashes.\n    n_threads = 10\n    barrier = threading.Barrier(n_threads)\n\n    # This object will be shared by all the threads.\n    cls_instance = MyClass(...)\n\n    def closure():\n        # Ensure that all threads reach this point before concurrent execution.\n        barrier.wait()\n        r = cls_instance.call_unsafe()\n        return r\n\n    with ThreadPoolExecutor(max_workers=n_threads) as executor:\n        futures = [executor.submit(closure) for _ in range(n_threads)]\n\n    results = [f.result() for f in futures]\n\n    # Do something about the results\n    assert check_results(results)\n</code></pre>"},{"location":"debugging/#debugging-tests-that-depend-on-native-calls","title":"Debugging tests that depend on native calls","text":"<p>If your code has native dependencies, either via C/C++ or Cython, <code>gdb</code> (or <code>lldb</code>) can be used as follows:</p> <pre><code># Setting PYTHON_GIL=0 ensures that the GIL is effectively disabled.\nPYTHON_GIL=0 gdb --args python my_program.py --args ...\n\n# To test under pytest\nPYTHON_GIL=0 gdb --args python -m pytest -x -v \"test_here.py::TestClass::test_method\"\n\n# Using LLDB (under LLVM/clang)\nPYTHON_GIL=0 lldb -- $(which python) my_program.py\n\n# Using LLDB (and pyenv)\nPYTHON_GIL=0 lldb -- $(pyenv which python) $(pyenv which pytest) -x -v \"test_here.py::TestClass::test_method\"\n</code></pre> <p>When Python is run under <code>gdb</code>, several Python integration commands will be available, such commands start with the <code>py-</code> prefix. For instance, the <code>py-bt</code> allows to obtain a Python interpreter backtrace whenever the debugger hits a native frame, this allows to improve the tracking of execution between Python and native frames<sup>1</sup>.</p> <p>For more information about <code>gdb</code> and <code>lldb</code> commands, we encourage reading the GDB to LLDB command map page in the official LLVM docs.</p>"},{"location":"debugging/#cython-debugging","title":"Cython debugging","text":"<p>Since Cython produces intermediate C/C++ sources that then are compiled into native code, stepping through may get difficult if done solely from the C source file. In order to get through such difficulty, Cython includes the <code>cygdb</code> extension, which enables <code>gdb</code> to go through large sections of C code that are equivalent to a single Cython declaration.</p> <p>Enabling <code>cygdb</code> requires the compilation of Cython sources with the <code>--gdb</code> flag. After the sources are compiled and linked, it can be used as follows:</p> <pre><code># For example, running the tests of scikit-image.\n# build/cp313td/ contains the trace files generated by Cython to be compatible\n# with cygdb\nPYTHON_GIL=0 cygdb build/cp313td/ -- --args python -m  pytest -x -v skimage/\n</code></pre> <p>Since <code>cygdb</code> requires the Python interpreter version used to compile <code>gdb</code> to match the one to be used during the execution of the script, recompiling <code>gdb</code> will be necessary in order to ensure the most complete debugging experience. We recommend the <code>gdb</code> compilation instructions provided by the Linux from scratch project.</p> <p><code>cygdb</code> defines a set of commands prefixed by <code>cy</code> that replace the usual <code>gdb</code> commands. For example <code>cy run</code> will start the program with the Cython debugging extensions enabled, <code>cy break</code> will define a breakpoint on a function with the Cython definition name, <code>cy next</code> will step over a Cython line, which is equivalent to several lines in the produced C code.</p>"},{"location":"debugging/#detecting-issues-in-cpython","title":"Detecting issues in CPython","text":"<p>If a debugging session suggests that an error/bug is incoming from CPython, we recommend installing a debug instance. The easiest way to accomplish this is via <code>pyenv</code>:</p> <pre><code>pyenv install --debug --keep 3.13.1\n</code></pre> <p>This command will not only install a debug distribution of CPython, but also will ensure that the source files are kept as well, such files will be loaded by <code>gdb</code>/<code>lldb</code> at the moment of debugging. For more information regarding CPython installation sources, please visit the Installing a free-threaded Python page.</p>"},{"location":"debugging/#frequently-seen-errors-and-how-to-fix-them","title":"Frequently seen errors and how to fix them","text":"<p>These are error messages that we see come up often when working with code or development workflows that have not been updated to accommodate the free-threaded build. We also provide suggested fixes. Please send in pull requests to the repository for this document if you run into any confusing free-threading-specific errors that you suspect apply to other libraries and aren't covered here.</p>"},{"location":"debugging/#cython-compilation-errors-unknown-type-name-__pyx_vectorcallfunc","title":"Cython compilation errors: <code>unknown type name '__pyx_vectorcallfunc'</code>","text":"<p>This happens if you try to build a Cython extension for the free-threaded build using the current stable release of Cython (3.0.11 at the time of writing). The current stable release of Cython does not support the free-threaded build. You must either build Cython from the <code>master</code> branch on Github or use the nightly wheel:</p> <pre><code>pip install -i https://pypi.anaconda.org/scientific-python-nightly-wheels/simple cython\n</code></pre> <p>See the porting guide for more detail about porting Cython code to work under free-threading.</p> <p>You may wonder why you are able to install a wheel for the current Cython release at all. This is because Cython ships a pure-python wheel tagged with <code>py2.py3-none-any</code>, which pip will install if it cannot find another wheel that is compatible. A future version of Cython will ship a wheel with compiled code that supports the free-threaded build.</p> <p>The current nightly wheel is a pure-python build, so it works on all architectures. The pure-python version of Cython is usually only marginally slower than a compiled version, so you should default to installing the wheel in CI instead of compiling Cython, which can take up to a few minutes on some CI runners.</p>"},{"location":"debugging/#compiling-cpython-and-foundational-packages-with-threadsanitizer","title":"Compiling CPython and foundational packages with ThreadSanitizer","text":"<p>Thread sanitizer (or TSan) helps to detect C/C++ data races in concurrent systems. This tool can help to reveal free-threading related bugs in CPython and foundational packages (e.g. <code>numpy</code>). In this section we provide the commands to build a free-threading compatible CPython interpreter and packages with ThreadSanitizer and other hints to discover potential data races.</p>"},{"location":"debugging/#cpython_sanity-docker-images","title":"<code>cpython_sanity</code> docker images","text":"<p>To ease working with thread sanitizer in projects that use Python, NumPy, and SciPy, we have create a set of docker images that contain a pre-built Python interpreter and common dependencies that can be tricky to build.</p> <p>See the <code>cpython_sanity</code> repository for more information about how to use the docker images.</p>"},{"location":"debugging/#compile-free-threaded-cpython-with-threadsanitizer","title":"Compile free-threaded CPython with ThreadSanitizer","text":"<ul> <li>Clone the latest stable branch (<code>3.13</code>):</li> </ul> <pre><code>git clone https://github.com/python/cpython.git -b 3.13\n</code></pre> <ul> <li>Configure and build the interpreter. Below instructions are for Linux     (Windows and macOS may require some changes). We skip the instructions on how     to install the Clang compiler.</li> </ul> <pre><code>cd cpython\nCC=clang-18 CXX=clang++-18 ./configure --disable-gil --with-thread-sanitizer --prefix $PWD/cpython-tsan\nmake -j 8\nmake install\n</code></pre> <ul> <li>To use the built Python interpreter:</li> </ul> <pre><code># Create a virtual environment:\n$PWD/cpython-tsan/bin/python3.13t -m venv ~/tsanvenv\n# Then activate it:\nsource ~/tsanvenv/bin/activate\n\npython -VV\n# Python 3.13.1 experimental free-threading build (tags/v3.13.1:06714517797, Dec 19 2024, 10:06:54) [Clang 18.1.3 (1ubuntu1)]\nPYTHON_GIL=0 python -c \"import sys; print(sys._is_gil_enabled())\"\n# False\n\n# Exit the `cpython` folder (preparation for the next step below)\ncd ..\n</code></pre> <p>If you use pyenv, you can also enable a thread sanitizer build with <code>pyenv install</code> like so:</p> <pre><code>CC=/path/to/clang CXX=/path/to/clang++ CONFIGURE_OPTS=\"--with-thread-sanitizer\" pyenv install 3.14t-dev\n</code></pre> <p>And then activate the build with e.g. <code>pyenv local 3.14t-dev</code>.</p> <p>Note</p> <p>On MacOS, you may see messages like this when you start Python:</p> <pre><code>python(7027,0x1f6dfc240) malloc: nano zone abandoned due to inability to reserve vm space.\n</code></pre> <p>This message is being emitted by the MacOS malloc implementation. As explained here, this happens for any program compiled with ThreadSanitizer on MacOS and can be safely ignored by setting the <code>MallocNanoZone</code> environment variable to 0. You should only set this in session you are running ThreadSanitizer under, as this setting will slow down other programs that allocate memory.</p>"},{"location":"debugging/#compile-numpy-with-threadsanitizer","title":"Compile NumPy with ThreadSanitizer","text":"<ul> <li>Get the source code (for example, the <code>main</code> branch)</li> </ul> <pre><code>git clone --recursive https://github.com/numpy/numpy.git\n</code></pre> <ul> <li>Install the build requirements:</li> </ul> <pre><code>cd numpy\npython -m pip install -r requirements/build_requirements.txt\n# Make sure to install a compatible Cython version (master branch is best for now)\npython -m pip install -U git+https://github.com/cython/cython\n</code></pre> <ul> <li>Build the package</li> </ul> <pre><code>CC=clang-18 CXX=clang++-18 python -m pip install -v . --no-build-isolation -Csetup-args=-Db_sanitize=thread\n# or with debug info\n# CC=clang-18 CXX=clang++-18 python -m pip install -v . --no-build-isolation -Csetup-args=-Db_sanitize=thread -Csetup-args=-Dbuildtype=debugoptimized\n</code></pre>"},{"location":"debugging/#running-python-under-threadsanitizer","title":"Running Python under ThreadSanitizer","text":""},{"location":"debugging/#useful-threadsanitizer-options","title":"Useful ThreadSanitizer options","text":"<ul> <li>By default ThreadSanitizer reports warnings. To stop execution on ThreadSanitizer errors, use:</li> </ul> <pre><code>TSAN_OPTIONS=halt_on_error=1 python -m pytest test.py\n</code></pre> <p>See the ThreadSanitizer documentation for a full listing of options accepted by ThreadSanitizer.</p> <ul> <li>To add ThreadSanitizer suppressions (written in a file: <code>tsan-suppressions</code>):</li> </ul> <pre><code># Let's show an example content of suppressions,\n# more info: https://github.com/google/sanitizers/wiki/ThreadSanitizerSuppressions\ncat $PWD/tsan-suppressions\n\nrace:llvm::RuntimeDyldELF::registerEHFrames\nrace:partial_vectorcall_fallback\nrace:dnnl_sgemm\n\n\nexport TSAN_OPTIONS=\"suppressions=$PWD/tsan-suppressions\" python -m pytest test.py\n</code></pre>"},{"location":"debugging/#running-pytest-tests-under-threadsanitizer","title":"Running pytest tests under ThreadSanitizer","text":"<p>By default, pytest captures all output from tests, this means that you might only see output like <code>ThreadSanitizer: reported 2 warnings</code>, but with no accompanying report with details about the warning.</p> <p>To ensure that pytest doesn't capture any output from ThreadSanitizer, you can pass <code>-s</code> (short for <code>--show-capture</code>) to your pytest invocation.</p> <p>Some authors of this guide have observed hangs running pytest with <code>halt_on_error=1</code>. If you observe hangs, try setting <code>halt_on_error=0</code> in TSAN_OPTIONS.</p> <p>The pytest-xdist plugin can also sometimes be problematic if a test runner happens to crash during execution. While <code>pytest-xdist</code> does have some support for detecting crashed worker, it is not foolproof and the authors of this guide have observed hangs on CI due to pytest-xdist not properly handling a worker failing due to a ThreadSanitizer error.</p> <p>The <code>pytest-xdist</code> plugin also makes it impossible to obtain stdout from a test runner, so there is no way to see ThreadSanitizer output if there is an issue. This can lead to hangs on CI machines with no accompanying error report to explain the nature of the hang. For that reason we suggest uninstalling <code>pytest-xdist</code> from your environment to ensure it isn't used. If you need to use <code>pytest-xdist</code> to make the tests complete in a reasonable amount of time, we suggest using <code>pytest-timeout</code> to ensure hung tests eventually exit, particularly on CI.</p> <p>ThreadSanitizer includes a check to ensure allocators never fail. This can lead to runtime crashes if a test happens to try allocating a very large block of memory specifically to ensure such an allocation does fail correctly. Set <code>allocator_may_return_null=1</code> in <code>TSAN_OPTIONS</code> to avoid this.</p> <p>If a ThreadSanitizer warning is detected, the exit code of the running process will be set to a nonzero value (66, by default). If for some reason that is problematic in your test suite then you can set <code>exitcode=0</code> in <code>TSAN_OPTIONS</code> to make ThreadSanitizer quit \"successfully\" if a warning is detected. For example, you might set this if a subprocess returning a nonzero exit code unexpectedly breaks a test.</p> <p>You might also find that running your test suite is very slow under ThreadSanitizer. Consider skipping tests that do not use threads, for example by only testing files that import <code>threading</code> or <code>concurrent.futures.ThreadPoolExecutor</code>. See this NumPy CI workflow that runs pytest on a subset of NumPy's tests. This will miss tests that spawn threads in native code (e.g. with OpenMP or other threading primitives) or use Python packages that spawn threads, but is a good option if your library doesn't do that.</p> <p>Altogether, a pytest invocation using ThreadSanitizer might look like:</p> <pre><code>$ TSAN_OPTIONS='allocator_may_return_null=1 halt_on_error=1' pytest -s\n</code></pre>"},{"location":"debugging/#using-addresssanitizer-to-detect-thread-safety-issues","title":"Using AddressSanitizer to detect thread safety issues","text":"<p>Since ThreadSanitizer adds significant overhead to both the Python interpreter and any native code compiled under ThreadSanitizer, many projects will be unable to run their full test suite under ThreadSanitizer in CI.</p> <p>For that reason, we also suggest setting up CI run for your full test suite using AddressSanitizer (or ASan). AddressSanitizer will detect if there are any memory safety issues triggered by multithreaded tests. While it will not detect data races that do not lead to observable memory safety issues, it will detect races that could lead to e.g. a segmentation fault and give precise debugging information about the nature of the memory safety issue. A developer could then look more closely at the issue using ThreadSanitizer outside of CI to more fully understand whether data races contributed to the memory safety issue.</p> <p>You can build Python with AddressSanitizer by passing <code>--with-address-sanitizer</code> to the CPython configure script. You can build NumPy with AddressSanitizer by passing <code>-Csetup-args=-Db_sanitize=address</code> as an argument to <code>pip install</code>.</p> <p>Like ThreadSanitizer, AddressSanitizer also accepts a number of options to control its behavior. See the documentation for more details. Note that both the CPython interpreter and many extensions have harmless memory leaks, so consider disabling the leak sanitizer built into AddressSanitizer by setting <code>ASAN_OPTIONS=\"detect_leaks=0\"</code>.</p> <ol> <li> <p>This feature is not correctly working on <code>lldb</code> after CPython 3.12.\u00a0\u21a9</p> </li> </ol>"},{"location":"installing_cpython/","title":"Installing Free-Threaded Python","text":"<p>To install a free-threaded CPython interpreter, you can either use a pre-built binary or build CPython from source. The former is quickest to get started with. Building from source is not too difficult either though, and in case you hit a bug that may involve CPython itself then you may want to build from source.</p>"},{"location":"installing_cpython/#binary-install-options","title":"Binary install options","text":"<p>There are a growing number of options to install a free-threaded interpreter, from the python.org installers to Linux distro and Conda package managers.</p> <p>Note</p> <p>For any of these options, please check after the install succeeds that you have a <code>pip</code> version that is recent enough (<code>&gt;=24.1</code>), and upgrade it if that isn't the case. Older <code>pip</code> versions will select wheels with the <code>cp313</code> tag (binary-incompatible) rather than the <code>cp313t</code> tag.</p> As a packager, what should I name the package and interpreter? <p>Please see this guidance from the Python Steering Council</p>"},{"location":"installing_cpython/#pythonorg-and-nuget-installers","title":"python.org and nuget installers","text":"<p>The python.org downloads page provides macOS and Windows installers that have experimental support.</p> <p>Note that you have to customize the install - e.g., for Windows there is a Download free-threaded binaries checkbox under \"Advanced Options\". See also the Using Python on Windows section of the Python 3.13 docs.</p> <p>Automating the process of downloading the official installers and installing the free-threaded binaries is also possible:</p> WindowsmacOS <p>Due to limitations of the Windows Python.org installer, using free-threaded Python installed from the Python.org installer may lead to trouble. In particular, if you install both a free-threaded and gil-enabled build of Python 3.13 using the Python.org installer, both installs will share a <code>site-packages</code> folder. This can very quickly lead to broken environments if packages for both versions are simultaneously installed.</p> <p>For that reason, we suggest using the <code>nuget</code> installer, which provides a separate <code>python-freethreaded</code> package that does not share an installation with the <code>python</code> package.</p> <pre><code>$url = 'https://www.nuget.org/api/v2/package/python-freethreaded/3.13.1'\nInvoke-WebRequest -Uri $url -OutFile 'python-freethreaded.3.13.1.nupkg'\nInstall-Package python-freethreaded -Scope CurrentUser -Source $pwd\n$python_dir = (Get-Item((Get-Package -Name python-freethreaded).Source)).DirectoryName\n$env:path = $python_dir + \"\\tools;\" + $python_dir + \"\\tools\\Scripts;\" + $env:Path\n</code></pre> <p>This will only modify your Path for the current Powershell session, so you will also need to permanently add the nuget package location to your Path to use it after closing the current session.</p> <p>If for some reason you need to use the Python.org installer, despite the problems described above, you can install it like so:</p> <pre><code>$url = 'https://www.python.org/ftp/python/3.13.1/python-3.13.1-amd64.exe'\nInvoke-WebRequest -Uri $url -OutFile 'python-3.13.1-amd64.exe'\n.\\python-3.13.1-amd64.exe /quiet Include_freethreaded=1\n</code></pre> <p>If you are running this script without administrator privileges, a UAC prompt will trigger when you try to run the installer. The resulting Python installation will be available afterwards in <code>AppData\\Local\\Programs\\Python\\Python313\\python3.13t.exe</code>. See Installing Without UI for more information.</p> <p>On macOS, you can use <code>installer</code> to install a macOS package you've downloaded:</p> <pre><code>curl -O https://www.python.org/ftp/python/3.13.1/python-3.13.1-macos11.pkg\n\n# create installer choice changes to customize the install:\n#    enable the PythonTFramework-3.13 package\n#    while accepting the other defaults (install all other packages)\ncat &gt; ./choicechanges.plist &lt;&lt;EOF\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"&gt;\n&lt;plist version=\"1.0\"&gt;\n&lt;array&gt;\n        &lt;dict&gt;\n                &lt;key&gt;attributeSetting&lt;/key&gt;\n                &lt;integer&gt;1&lt;/integer&gt;\n                &lt;key&gt;choiceAttribute&lt;/key&gt;\n                &lt;string&gt;selected&lt;/string&gt;\n                &lt;key&gt;choiceIdentifier&lt;/key&gt;\n                &lt;string&gt;org.python.Python.PythonTFramework-3.13&lt;/string&gt;\n        &lt;/dict&gt;\n&lt;/array&gt;\n&lt;/plist&gt;\nEOF\n\nsudo installer -pkg ./python-3.13.1-macos11.pkg \\\n    -applyChoiceChangesXML ./choicechanges.plist \\\n    -target /\nrm -f python-3.13.1-macos11.pkg\n</code></pre> <p>See also this Github issue for more information.</p>"},{"location":"installing_cpython/#linux-distros","title":"Linux distros","text":"FedoraNixpkgsUbuntu <p>Fedora ships a packaged version, which you can install with:</p> <pre><code>sudo dnf install python3.13-freethreading\n</code></pre> <p>This will install the interpreter at <code>/usr/bin/python3.13t</code>.</p> <p>Nixpkgs provides cached builds under the <code>python313FreeThreading</code> attribute from NixOS 24.05 and newer.</p> <p>With <code>flakes</code> enabled the following command will drop you in an ephemeral shell:</p> <pre><code>nix shell nixpkgs#python313FreeThreading\n</code></pre> <p>Without <code>flakes</code>, make sure to update your nixpkgs channel first:</p> <pre><code>sudo nix-channel --update\nnix-shell -p python313FreeThreading\n</code></pre> <p>For Ubuntu you can use the deadsnakes PPA by adding it to your repositories and then installing <code>python3.13-nogil</code>:</p> <pre><code>sudo add-apt-repository ppa:deadsnakes\nsudo apt-get update\nsudo apt-get install python3.13-nogil\n</code></pre>"},{"location":"installing_cpython/#multi-platform-package-managers","title":"Multi-platform Package Managers","text":"Conda-forgeAnaconda TestingHomebrew <pre><code>mamba create -n nogil -c conda-forge python-freethreading\n</code></pre> <p>or with conda:</p> <pre><code>conda create -n nogil --override-channels -c conda-forge python-freethreading\n</code></pre> <p>Anaconda's test channel includes the Python interpreter and ABI-compatible builds of many common packages, like NumPy, Cython, Pandas, etc. These packages use the <code>python_abi</code> metapackage and should be compatible with conda-forge:</p> <pre><code>conda create -n nogil --override-channels -c ad-testing/label/py313 -c https://repo.anaconda.com/pkgs/main python-freethreading\n</code></pre> <p>Full list of Anaconda test packages built with free-threading ABI.</p> <p>On macOS and Linux, you can use Homebrew:</p> <pre><code>brew install python-freethreading\n</code></pre> <p>This will install the interpreter at <code>$(brew --prefix)/bin/python3.13t</code>.</p> <p>On macOS, the Python framework built with the free-threading ABI can be found at <code>$(brew --prefix)/Frameworks/PythonT.framework</code>.</p>"},{"location":"installing_cpython/#installing-a-jupyter-kernel","title":"Installing a Jupyter Kernel","text":"<p>While Jupyter does not currently support free-threaded Python, you can use Jupyter with a regular build of Python and a free-threaded Jupyter kernel. To do so, install the kernel to a location that is visible to both Python installations:</p> <pre><code>python3.13t -m ipykernel install --name python3.13t --user\n</code></pre> <p>And then you should be able to launch new jupyterlab or jupyter notebook sessions using the <code>python3.13t</code> kernel to experiment with free-threaded Python.</p>"},{"location":"installing_cpython/#containers","title":"Containers","text":"<p>The manylinux containers have free-threaded builds. You can use any of the actively supported images:</p> <ul> <li><code>quay.io/pypa/manylinux2014_...</code></li> <li><code>quay.io/pypa/manylinux_2_28_...</code></li> <li><code>quay.io/pypa/musllinux_1_1_...</code></li> <li><code>quay.io/pypa/musllinux_1_2_...</code></li> </ul> <p>Replace <code>...</code> with your desired architecture, such as <code>x86_64</code> or <code>aarch64</code>.</p> <p>These images have <code>python3.13t</code> available, along with other commonly used tools that can target it like the latest <code>pip</code>, <code>pipx</code>, and <code>uv</code>.</p>"},{"location":"installing_cpython/#building-from-source","title":"Building from source","text":"<p>Currently we suggest building CPython from source using the latest version of the CPython <code>main</code> branch. See the build instructions in the CPython developer guide. You will need to install needed third-party dependencies before building. To build the free-threaded version of CPython, pass <code>--disable-gil</code> to the <code>configure</code> script:</p> <pre><code>./configure --with-pydebug --disable-gil\n</code></pre> <p>If you will be switching Python versions often, it may make sense to build CPython using pyenv. In order to do that, you can use the following:</p> <pre><code>pyenv install --debug --keep 3.13.1\n</code></pre>"},{"location":"porting-extensions/","title":"Updating Extension Modules","text":"<p>Here we are going to re-hash some of the same topics covered in the previous section but with a focus on advice for updating native extension modules, particularly modules relying directly on the CPython C API. The general advice remains the same: identify supported multithreaded workflows, add testing, and fix and identified thread safety issues. We will also describe how to handle some common thread-unsafe patterns we have found in many extension modules across the open source ecosystem.</p>"},{"location":"porting-extensions/#declaring-free-threaded-support","title":"Declaring free-threaded support","text":"<p>Extension modules need to explicitly indicate they support running with the GIL disabled, otherwise a warning is printed and the GIL is re-enabled at runtime after importing a module that does not support the GIL.</p> C APIPybind11CythonRustf2py <p>C or C++ extension modules using multi-phase initialization can specify the <code>Py_mod_gil</code> module slot like this:</p> <pre><code>static PyModuleDef_Slot module_slots[] = {\n    ...\n#ifdef Py_GIL_DISABLED\n    {Py_mod_gil, Py_MOD_GIL_NOT_USED},\n#endif\n    {0, NULL}\n};\n</code></pre> <p>The <code>Py_mod_gil</code> slot has no effect in the non-free-threaded build.</p> <p>Extensions that use single-phase initialization need to call <code>PyUnstable_Module_SetGIL()</code> in the module's initialization function:</p> <pre><code>PyMODINIT_FUNC\nPyInit__module(void)\n{\n    PyObject *mod = PyModule_Create(&amp;module);\n    if (mod == NULL) {\n        return NULL;\n    }\n\n#ifdef Py_GIL_DISABLED\n    PyUnstable_Module_SetGIL(mod, Py_MOD_GIL_NOT_USED);\n#endif\n\n    return mod;\n}\n</code></pre> <p>C++ extension modules making use of <code>pybind11</code> can easily declare support for running with the GIL disabled via the <code>gil_not_used</code> argument to <code>create_extension_module</code>. Example:</p> <pre><code>#include &lt;pybind11/pybind11.h&gt;\nnamespace py = pybind11;\n\nPYBIND11_MODULE(example, m, py::mod_gil_not_used()) {\n    ...\n}\n</code></pre> <p>Cython code can be thread-unsafe and just like C and C++ code can exhibit undefined behavior due to data races.</p> <p>Code operating on Python objects should not exhibit any low-level data corruption or C undefined behavior due to Python-level semantics. If you find such a case, it may be a Cython or CPython bug and should be reported as such.</p> <p>That said, as opposed to data races, race conditions that produces random results from a multithreaded algorithm are not undefined behavior and are allowed in Python and therefore Cython as well. You will still need to add locking or synchronization where appropriate to ensure reproducible results when running a multithreaded algorithm on shared mutable data. See the suggested plan of attack below for more details about discovering and fixing thread safety issues for Python native extensions.</p> <p>Starting with Cython 3.1.0 (available via the nightly wheels, a PyPI pre-release or the <code>master</code> branch as of right now), extension modules written in Cython can do so using the <code>freethreading_compatible</code> compiler directive.</p> <p>You can do this in one of several ways, e.g., in a source file:</p> <pre><code># cython: freethreading_compatible=True\n</code></pre> <p>Or by passing the directive when invoking the <code>cython</code> executable:</p> <pre><code>$ cython -X freethreading_compatible=True\n</code></pre> <p>Or via a build system specific way of passing directives to Cython.</p> <p>Tip</p> <p>Here are a few examples of how to globally enable the directive in a few popular build systems:</p> setuptoolsMeson <p>When using setuptools, you can pass the <code>compiler_directives</code> keyword argument to <code>cythonize</code>:</p> <pre><code>from Cython.Compiler.Version import version as cython_version\nfrom packaging.version import Version\n\ncompiler_directives = {}\nif Version(cython_version) &gt;= Version(\"3.1.0a0\"):\n    compiler_directives[\"freethreading_compatible\"] = True\n\nsetup(\n    ext_modules=cythonize(\n        extensions,\n        compiler_directives=compiler_directives,\n    )\n)\n</code></pre> <p>When using Meson, you can add the directive to the <code>cython_args</code> you're passing to <code>py.extension_module</code>:</p> <pre><code>cy = meson.get_compiler('cython')\n\ncython_args = []\nif cy.version().version_compare('&gt;=3.1.0')\n    cython_args += ['-Xfreethreading_compatible=True']\nendif\n\npy.extension_module('modulename'\n    'source.pyx',\n    cython_args: cython_args,\n    ...\n)\n</code></pre> <p>You can also globally add the directive for all Cython extension modules:</p> <pre><code>cy = meson.get_compiler('cython')\nif cy.version().version_compare('&gt;=3.1.0')\n    add_project_arguments('-Xfreethreading_compatible=true', language : 'cython')\nendif\n</code></pre> <p>In CI, you will need to ensure a nightly cython is installed for free-threaded builds. See the docs on setting up CI for advice on how to build projects that depend on Cython.</p> <p>If you use the CPython C API via PyO3, then you can follow the PyO3 Guide section on supporting free-threaded Python. You must also update your extension to at least version 0.23.</p> <p>You should write multithreaded tests of any code you expose to Python. See the details about testing in our suggested plan of attack below as well as the guidance for updating test suites. You should fix any thread safety issues you discover while running multithreaded tests.</p> <p>As of PyO3 0.23, PyO3 enforces Rust's borrow checking rules at runtime and may produce runtime panics if you simultaneously mutably borrow data in more than one thread. You may want to consider storing state in using atomic data structures, with mutexes or locks, or behind <code>Arc</code> pointers.</p> <p>Once you are satisfied the Python modules defined by your rust crate are thread safe, you can pass <code>gil_used = false</code> to the <code>pymodule</code> macro:</p> <pre><code>#[pymodule(gil_used = false)]\nfn my_module(py: Python, m: &amp;Bound&lt;'_, PyModule&gt;) -&gt; PyResult&lt;()&gt; {\n    ...\n}\n</code></pre> <p>If you define any modules procedurally by manually creating a <code>PyModule</code> struct without using the <code>pymodule</code> macro, you can call <code>PyModuleMethods::gil_used</code> after instantiating the module.</p> <p>If you use the <code>pyo3-ffi</code> crate and/or <code>unsafe</code> FFI calls to call directly into the C API, then see the section on porting C extensions in this guide as well as the PyO3 source code.</p> <p>Starting with NumPy 2.1.0, extension modules containing f2py-wrapped Fortran code can declare they are thread-safe and support free-threading using the <code>--freethreading-compatible</code> command-line argument:</p> <pre><code>$ python -m numpy.f2py -c code.f -m my_module --freethreading-compatible\n</code></pre> <p>If you publish binaries and have downstream libraries that depend on your library, we suggest adding support as described above and uploading nightly wheels as soon as basic support for the free-threaded build is established in the development branch. This will ease the work of libraries that depend on yours to also add support for the free-threaded build.</p>"},{"location":"porting-extensions/#porting-c-extensions","title":"Porting C Extensions","text":"<p>The CPython C API exposes the <code>Py_GIL_DISABLED</code> macro in the free-threaded build. You can use it to enable low-level code that only runs under the free-threaded build, isolating possibly performance-impacting changes to the free-threaded build:</p> <pre><code>#ifdef Py_GIL_DISABLED\n// free-threaded specific code goes here\n#endif\n\n#ifndef Py_GIL_DISABLED\n// code for gil-enabled builds goes here\n#endif\n</code></pre>"},{"location":"porting-extensions/#locking-and-synchronization-primitives","title":"Locking and Synchronization Primitives","text":""},{"location":"porting-extensions/#native-mutexes","title":"Native mutexes","text":"<p>If your extension is written in C++, Rust, or another modern language that exposes locking primitives in the standard library, you should consider using the locking primitives provided by your language or framework to add locks when needed.</p> <p>If you need to call arbitrary Python code while the lock is held, care should be taken to avoid creating deadlocks with the GIL on the GIL-enabled build.</p>"},{"location":"porting-extensions/#pymutex","title":"<code>PyMutex</code>","text":"<p>For C code or C-like C++ code, the CPython 3.13 C API exposes <code>PyMutex</code>, a high-performance locking primitive that supports static allocation. As of CPython 3.13, the mutex requires only one byte for storage, but future versions of CPython may change that, so you should not rely on the size of <code>PyMutex</code> in your code.</p> <p>You can use <code>PyMutex</code> in both the free-threaded and GIL-enabled build of Python 3.13 or newer. <code>PyMutex</code> is hooked into the CPython runtime, so that if a thread tries to acquire the mutex and ends up blocked, garbage collection can still proceed and, in the GIL-enabled build, the blocked thread releases the GIL, allowing other threads to continue running. This implies that it is impossible to create a deadlock between a <code>PyMutex</code> and the GIL. For this reason, it is not necessary to add code for the GIL-enabled build to ensure the GIL is released before acquiring a <code>PyMutex</code>. If you do not call into the CPython C API while holding the lock, <code>PyMutex</code> has no special advantages over other mutexes, besides low-level details like performance or the size of the mutex object in memory.</p> <p>See the section on dealing with thread-unsafe low-level libraries below for an example using PyMutex to lock around a thread-unsafe C library.</p>"},{"location":"porting-extensions/#critical-sections","title":"Critical Sections","text":"<p>Python 3.13 or newer also offers a critical section API that is useful for locking either a single object or a pair of objects during a low-level operation. The critical section API is intended to provide weaker, but still useful locking guarantees compared to directly locking access to an object using a mutex. This provides similar guarantees to the GIL and avoids the risk of deadlocks introduced by locking individual objects.</p> <p>The main difference compared with using a per-object lock is that active critical sections are suspended if a thread calls <code>PyEval_SaveThread</code> (e.g. when the GIL is released on the GIL-enabled build), and then restored when the thread calls <code>PyEval_RestoreThread</code> (e.g. when the GIL is re-acquired on the GIL-enabled build). This means that while the critical sections are suspended, it's possible for any thread to re-acquire a thread state and mutate the locked object. This can also happen with the GIL, since the GIL is a re-entrant lock, and extensions are allowed to recursively release and acquire it in an interleaved manner.</p> <p>Critical sections are most useful when implementing the low-level internals of a custom object that you fully control. You can apply critical sections around modification of internal state to effectively serialize access to that state.</p> <p>See the section below on dealing with thread-unsafe objects for an example using the critical section API.</p>"},{"location":"porting-extensions/#dealing-with-global-state","title":"Dealing with global state","text":"<p>Many CPython C extensions make strong assumptions about the GIL. For example, before NumPy 2.1.0, the C code in NumPy made extensive use of C static global variables for storing settings, state, and caches. With the GIL, it is possible for Python threads to produce non-deterministic results from a calculation, but it is not possible for two C threads to simultaneously see the state of the C global variables, so no data races are possible.</p> <p>In free-threaded Python, global state like this is no longer safe against data races and undefined behavior in C code. A cache of <code>PyObject</code> pointers stored in a C global array can be overwritten simultaneously by multiple Python threads, leading to memory corruption and segfaults.</p>"},{"location":"porting-extensions/#converting-global-state-to-thread-local-state","title":"Converting global state to thread local-state","text":"<p>Often the easiest way to fix data races due to global state is to convert the global state to thread local state.</p> <p>Python and Cython code can make use of <code>threading.local</code> to declare a thread-local Python object. C and C++ code can also use the <code>Py_tss API</code> to store thread-local Python object references. PEP 539 has more details about the <code>Py_tss</code> API.</p> <p>Low-level C or C++ code can make use of the <code>thread_local</code> storage specified by recent standard versions. Note that standardization of thread-local storage in C has been slower than C++, so you may need to use platform-specific definitions to declare variables with thread-local storage. Also note that thread-local storage on MSVC has caveats, and you should not use thread-local storage for anything besides statically defined integers and pointers.</p> <p>NumPy has a <code>NPY_TLS</code> macro in the <code>numpy/npy_common.h</code> header. While you can include the numpy header and use <code>NPY_TLS</code> directly on NumPy 2.1 or newer, you can also add the definition to your own codebase, along with some build configuration tests to test for the correct definition to use.</p>"},{"location":"porting-extensions/#making-global-caches-thread-safe","title":"Making global caches thread-safe","text":"<p>Global caches are also a common source of thread safety issues. For example, if a function requires an expensive intermediate result that only needs to be calculated once, many C extensions store the result in a global variable. This can lead to data races and memory corruption if more than one thread simultaneously tries to fill the cache.</p> <p>If the cache is not critical for performance, consider simply disabling the cache in the free-threaded build:</p> <pre><code>static int *cache = NULL;\n\nint my_function_with_a_cache(void) {\n    int *my_cache = NULL;\n#ifndef Py_GIL_DISABLED\n    if (cache == NULL) {\n        cache = get_expensive_result();\n    }\n    my_cache = cache;\n#else\n    my_cache = get_expensive_result();\n#endif;\n    // use the cache\n}\n</code></pre> <p>CPython holds a per-module lock during import. This lock can be released to avoid deadlocks in unusual cases, but in most situations module initialization happens exactly once per interpreter in one C thread. Modules using static single-phase initialization can therefore set up per-module state in the <code>PyInit</code> function without worrying about concurrent initialization of modules in different threads. For example, you might set up a global static cache that is read-only after module initialization like this:</p> <pre><code>static int *cache = NULL;\n\nPyMODINIT_FUNC\nPyInit__module(void)\n{\n    PyObject *mod = PyModule_Create(&amp;module);\n    if (mod == NULL) {\n        return NULL;\n    }\n\n    // don't need to lock or do anything special\n    cache = setup_cache();\n\n    // do rest of initialization\n}\n</code></pre> <p>You can then read from <code>cache</code> at runtime in a context where you know the module is initialized without worrying about whether or not the per-module static cache is initialized.</p> <p>If the cache is critical for performance, cannot be generated at import time, but generally gets filled quickly after a program begins, then you will need to use a single-initialization API to ensure the cache is only ever initialized once. In C++, use <code>std::once_flag</code> or <code>std::call_once</code>.</p> <p>C does not have an equivalent portable API for single initialization. If you need that, take a look at this NumPy PR for an example using atomic operations and a global mutex.</p> <p>If the cache is in the form of a data container, then you can lock access to the container, like in the following example:</p> <pre><code>#ifdef Py_GIL_DISABLED\nstatic PyMutex cache_lock = {0};\n#define LOCK() PyMutex_Lock(&amp;cache_lock)\n#define UNLOCK() PyMutex_Unlock(&amp;cache_lock)\n#else\n#define LOCK()\n#define UNLOCK()\n#endif\n\nstatic int *cache = NULL;\nstatic PyObject *global_table = NULL;\n\nint initialize_table(void) {\n    // called during module initialization\n    global_table = PyDict_New();\n    return;\n}\n\nint function_accessing_the_cache(void) {\n    LOCK();\n    // use the cache\n\n    UNLOCK();\n}\n</code></pre> <p>Note</p> <p>Note that, while the NumPy PR linked above uses <code>PyThread_type_lock</code>, that is only because <code>PyMutex</code> was not part of the public Python C API at the time. We recommend always using <code>PyMutex</code>. For pointers on how to do that, check this NumPy PR that ports all <code>PyThread_type_lock</code> usages to <code>PyMutex</code>.</p>"},{"location":"porting-extensions/#dealing-with-thread-unsafe-native-libraries","title":"Dealing with thread-unsafe native libraries","text":"<p>Many C, C++, and Fortran libraries are not written in a thread-safe manner. It is still possible to call these libraries from free-threaded Python, but wrappers must add appropriate locks to prevent undefined behavior.</p> <p>There are two kinds of thread unsafe libraries: reentrant and non-reentrant. A reentrant library generally will expose state as a struct that must be passed to library functions. So long as the state struct is not shared between threads, functions in the library can be safely executed simultaneously.</p> <p>Wrapping reentrant libraries requires adding locking whenever the state struct is accessed.</p> <pre><code>typedef struct lib_state_struct {\n    low_level_library_state *state;\n    PyMutex lock;\n} lib_state_struct;\n\nint call_library_function(lib_state_struct *lib_state) {\n    PyMutex_Lock(&amp;lib_state-&gt;lock);\n    library_function(lib_state-&gt;state);\n    PyMutex_Unlock(&amp;lib_state-&gt;lock)\n}\n\nint call_another_library_function(lib_state_struct *lib_state) {\n    PyMutex_Lock(&amp;lib_state-&gt;lock);\n    another_library_function(lib_state-&gt;state);\n    PyMutex_Unlock(&amp;lib_state-&gt;lock)\n}\n</code></pre> <p>With this setup, if two threads call <code>library_function</code> and <code>another_library_functions</code> simultaneously, one thread will block until the other thread finishes, preventing concurrent access to <code>lib_state-&gt;state</code>.</p> <p>Non-reentrant libraries provide an even weaker guarantee: threads cannot call library functions simultaneously without causing undefined behavior. Generally this is due to use of global static state in the library. This means that non-reentrant libraries require a global lock:</p> <pre><code>static PyMutex global_lock = {0};\n\nint call_library_function(int *argument) {\n    PyMutex_Lock(&amp;global_lock);\n    library_function(argument);\n    PyMutex_Unlock(&amp;global_lock);\n}\n</code></pre> <p>Any other wrapped function needs similar locking around each call into the library.</p>"},{"location":"porting-extensions/#dealing-with-thread-unsafe-objects","title":"Dealing with thread-unsafe objects","text":"<p>Similar to the section above, objects may need locking or atomics if they can be concurrently modified from multiple threads. CPython 3.13 exposes a public C API that allows users to use the built-in per-object locks.</p> <p>For example the following code:</p> <pre><code>int do_modification(MyObject *obj) {\n    return modification_on_obj(obj);\n}\n</code></pre> <p>Should be transformed to:</p> <pre><code>int do_modification(MyObject *obj) {\n    int res;\n    Py_BEGIN_CRITICAL_SECTION(obj);\n    res = modification_on_obj(obj);\n    Py_END_CRITICAL_SECTION(obj);\n    return res;\n}\n</code></pre> <p>A variant for locking two objects at once is also available. For more information about <code>Py_BEGIN_CRITICAL_SECTION</code>, please see the Python C API documentation on critical sections.</p>"},{"location":"porting-extensions/#cython-thread-safety","title":"Cython thread safety","text":"<p>If your extension is written in Cython, you can generally assume that \"Python-level\" code that compiles to CPython C API operations on Python objects is thread-safe, but \"C-level\" code (e.g. code that will compile inside a <code>with nogil</code> block) may have thread safety issues. Note that not all code outside <code>with nogil</code> blocks is thread-safe. For example, a Python wrapper for a thread-unsafe C library is thread-unsafe if the GIL is disabled unless there is locking around uses of the thread-unsafe library. Another example: using thread-unsafe C-level constructs like a global variable is also thread-unsafe if the GIL is disabled.</p>"},{"location":"porting-extensions/#cpython-c-api-usage","title":"CPython C API usage","text":"<p>In the free-threaded build it is possible for the reference count of an object to change \"underneath\" a running thread when it is mutated by another thread. This means that many APIs that assume reference counts cannot be updated by another thread while it is running are no longer thread-safe. In particular, C code returning \"borrowed\" references to Python objects in mutable containers like lists may introduce thread safety issues. A borrowed reference happens when a C API function does not increment the reference count of a Python object before returning the object to the caller. \"New\" references are safe to use until the owning thread releases the reference, as in non free-threaded code.</p> <p>Most direct uses of the CPython C API are thread-safe. There is no need to add locking for scenarios that should be bugs in CPython. You can assume, for example, that the initializer for a Python object can only be called by one thread and the C-level implementation of a Python function can only be called on one thread. Accessing the arguments of a Python function is thread-safe no matter what C API constructs are used and no matter whether the reference is borrowed or owned because two threads can't simultaneously call the same function with the same arguments from the same Python-level context. Of course it's possible to implement argument parsing in a thread-unsafe manner using thread-unsafe C or C++ constructs, but it's not possible to do so using the CPython C API.</p>"},{"location":"porting-extensions/#unsafe-apis-returning-borrowed-references","title":"Unsafe APIs returning borrowed references","text":"<p>The <code>PyDict</code> and <code>PyList</code> APIs contain many functions returning borrowed references to items in dicts and lists. Since these containers are mutable, it's possible for another thread to delete the item from the container, leading to the item being de-allocated while the borrowed reference is still \"alive\". Even code like this:</p> <pre><code>PyObject *item = Py_NewRef(PyList_GetItem(list_object, 0))\n</code></pre> <p>Is not thread-safe, because in principle it's possible for the list item to be de-allocated before <code>Py_NewRef</code> gets a chance to increment the reference count.</p> <p>For that reason, you should inspect Python C API code to look for patterns where a borrowed reference is returned to a shared, mutable data structure, and replace uses of APIs like <code>PyList_GetItem</code> with APIs exposed by the CPython C API returning strong references like <code>PyList_GetItemRef</code>. Not all usages are problematic (see above) and we do not currently suggest converting all usages of possibly unsafe APIs returning borrowed references to return new reference. This would introduce unnecessary reference count churn in situations that are thread-safe by construction and also likely introduce new reference counting bugs in C or C++ code using the C API directly. However, many usages are unsafe, and maintaining a borrowed reference to an objects that could be exposed to another thread is unsafe.</p> <p>A good starting place to find instances of this would be to look for usages of the unsafe borrowed reference APIs mentioned in the free-threading compatibility docs.</p>"},{"location":"porting-extensions/#adopt-pythoncapi-compat-to-use-new-c-api-functions","title":"Adopt <code>pythoncapi-compat</code> to use new C API functions","text":"<p>Rather than maintaining compatibility shims to use functions added to the C API for Python 3.13 like <code>PyList_GetItemRef</code> while maintaining compatibility with earlier Python versions, we suggest adopting the <code>pythoncapi-compat</code> project as a build-time dependency. This is a header-only library that can be vendored as e.g. a git submodule and included to expose shims for C API functions on older versions of Python that do not have implementations.</p>"},{"location":"porting-extensions/#some-low-level-apis-dont-enforce-locking","title":"Some low-level APIs don't enforce locking","text":"<p>Some low-level functions like <code>PyList_SET_ITEM</code> and <code>PyTuple_SET_ITEM</code> do not do any internal locking and should only be used to build newly created values. Do not use them to modify existing containers in the free-threaded build.</p>"},{"location":"porting-extensions/#limited-api-support","title":"Limited API support","text":"<p>The free-threaded build does not support the limited CPython C API. If you currently use the limited API to build wheels that do not depend on a specific Python version, you will not be able to use it while shipping binaries for the free-threaded build. In practice, the limited API is a subset of the full C API, so your extension will build, you just cannot set <code>Py_LIMITED_API</code> at build time. This also means that code inside <code>#ifdef Py_GIL_DISABLED</code> checks can use C API constructs outside the limited API if you would like to do that, although these uses will need to be removed once the free-threaded build gains support for compiling with the limited API.</p>"},{"location":"porting/","title":"Porting Python Packages to Support Free-Threading","text":"<p>Many Python packages, particularly packages relying on C extension modules, are not thread-safe in the free-threaded build as of mid-2024. Up until now, the GIL has added implicit locking around any operation in Python or C that holds the GIL, and the GIL must be explicitly dropped before many thread safety issues become problematic. Also, because of the GIL, attempting to parallelize many workflows using the Python threading module will not produce any speedups, so thread safety issues that are possible even with the GIL are not hit often since users do not make use of threading as much as other parallelization strategies. This means many codebases have threading bugs that up-until-now have only been theoretical or present in niche use cases. With free-threading, many more users will want to use Python threads.</p> <p>This means we must analyze Python codebases to identify supported and unsupported multithreaded workflows and make changes to fix thread safety issues. This need is particularly acute for low-level code exposed to Python including C, C++, Cython, and Rust code exposed to Python, but even pure Python codebases can exhibit non-determinism and racies in the free-threaded build that are either very unlikely or impossible in the default configuration of the GIL-enabled build.</p>"},{"location":"porting/#suggested-plan-of-attack","title":"Suggested Plan of Attack","text":"<p>Below, we outline a plan of attack for updating a Python project to support the free-threaded build. Since the changes required in native extensions are more substantial, we have split off the guide for porting extension modules into a subsequent section.</p>"},{"location":"porting/#thread-safety-of-pure-python-code","title":"Thread Safety of Pure Python Code","text":"<p>The CPython interpreter protects you from low-level memory unsafety due to data races. It does not protect you from introducing thread safety issues due to race conditions. It is possible to write algorithms that depend on the precise timing of threads completing work. That means it is up to you as a user of multithreaded parallelism to ensure that any resources that need protection from multithreaded access or mutation are appropriately protected.</p> <p>Below we describe various approaches for improving the determinism of multithreaded pure Python code. The correct approach will depend on exactly what you are doing.</p>"},{"location":"porting/#general-considerations-for-porting","title":"General considerations for porting","text":"<p>Many projects assume the GIL serializes access to state shared between threads, introducing the possibility of data races in native extensions and race conditions that are impossible when the GIL is enabled.</p> <p>We suggest focusing on safety over single-threaded performance. For example, if adding a lock to a global cache would harm multithreaded scaling, and turning off the cache implies a small performance hit, consider doing the simpler thing and disabling the cache in the free-threaded build. Single-threaded performance can always be improved later, once you've established free-threaded support and hopefully improved test coverage for multithreaded workflows.</p> <p>NumPy, for example, decided not to add explicit locking to the ndarray object and does not support mutating shared ndarrays. This was a pragmatic choice given existing heavy multithreaded use of NumPy in the GIL-enabled build and a desire to not introducing scaling bottlenecks in existing workflows.</p> <p>Eventually NumPy may need to offer explicitly thread-safe data structures, but it is a valid choice to initially support free-threading while still exposing possibly unsafe operations if users use the library unsafely.</p> <p>For pure Python packages, a racey algorithm might result in unexpected exceptions or silently incorrect results. Projects shipping extension modules might additionally see crashes or trigger undefined behavior. See the section on supporting native code if you are curious about supporting compiled Python extensions in the free-threaded build.</p> <p>For your libraries, we suggest to focus on thread safety issues that only occur with the GIL disabled. Any non-critical preexisting thread safety issues can be dealt with later once the free-threaded build is used more. The goal for your initial porting effort should be to enable further refinement and experimentation by fixing issues that prevent using the library at all.</p>"},{"location":"porting/#multithreaded-python-programming","title":"Multithreaded Python Programming","text":"<p>The Python standard library offers a rich API for multithreaded programming. This includes the <code>threading</code> module, which offers relatively low-level locking and synchronization primitives, as well as the <code>queue module</code> and the <code>ThreadPoolExecutor</code> high-level thread pool interface.</p> <p>If you'd like to learn more about multithreaded Python programming in the GIL-enabled build, Santiago Basulto's tutorial from PyCon 2020 is a good place to start.</p> <p>For a pedagogical introduction to multithreaded programming in free-threaded Python, we suggest reading the <code>ft_utils</code> documentation, particularly the section on the impact of the global interpreter lock on multithreaded Python programs. Many pure Python operations are not atomic and are susceptible to race conditions, or only appear to be thread-safe in the GIL-enabled build because of details of how CPython releases the GIL in a round-robin fasion to allow threads to run.</p> <p>Both the <code>ft_utils</code> and <code>cereggii</code> libraries offer data structures that add enhanced atomicity to standard library primitives. We hope these sorts of tools to aid concurrent free-threaded programming continue to pop up and evolve, as they will be key to enabling scalable multithreaded workflows.</p>"},{"location":"porting/#dealing-with-mutable-global-state","title":"Dealing with mutable global state","text":"<p>The most common source of thread safety issues in Python packages is use of global mutable state. Many projects use module-level or class-level caches to speed up execution but do not envision filling the cache simultaneously from multiple threads. See the testing guide for strategies to add tests to detect problematic global state.</p> <p>For example, the <code>do_calculation</code> function in the following module is not thread-safe:</p> <pre><code>from internals import _do_expensive_calculation\n\nglobal_cache = {}\n\n\ndef do_calculation(arg):\n    if arg not in global_cache:\n        global_cache[arg] = _do_expensive_calculation(arg)\n    return global_cache[arg]\n</code></pre> <p>If <code>do_calculation</code> is called simultaneously in multiple threads, then it is possible for at least two threads to see that <code>global_cache</code> doesn't have the cached key and call <code>_do_expensive_calculation</code>. In some cases this is harmless, but depending on the nature of the cache, this could lead to unnecessary network access, resource leaks, or wasted unnecessary compute cost.</p>"},{"location":"porting/#converting-global-state-to-thread-local-state","title":"Converting global state to thread-local state","text":"<p>One way of dealing with issues like this is to convert a shared global cache into a thread-local cache. In this apprach, each thread will see its own private copy of the cache, making races between threads impossible. This approach makes sense if having extra copies of the cache in each thread is not prohibitively expensive or does not lead to excessive runtime network, CPU, or memory use.</p> <p>In pure Python, you can create a thread-local cache using an instance of threading.local. Each thread will see independent versions of the thread-local object. You could rewrite the above example to use a thread-local cache like so:</p> <pre><code>import threading\n\nfrom internals import _do_expensive_calculation\n\nlocal = threading.local()\n\nlocal.cache = {}\n\n\ndef do_calculation(arg):\n    if arg not in local.cache:\n        local.cache[arg] = _do_expensive_calculation(arg)\n    return local.cache[arg]\n</code></pre> <p>This wouldn't help a case where each thread having a copy of the cache would be prohibitive, but it does fix possible issues with resource leaks issues due to races filling a cache.</p>"},{"location":"porting/#making-mutable-global-caches-thread-safe-with-locking","title":"Making mutable global caches thread-safe with locking","text":"<p>If a thread-local cache doesn't make sense, then you can serialize access to the cache with a lock. A lock provides exclusive access to some resource by forcing threads to acquire a lock instance before they can use the resource and release the lock when they are done. The lock ensures that only one thread at a time can use the acquired lock - all other threads block execution until the thread that holds the lock releases it, at which point only one thread waiting to acquire the lock is allowed to run.</p> <p>You could rewrite the above thread-unsafe example to be thread-safe using a lock like this:</p> <pre><code>import threading\n\nfrom internals import _do_expensive_calculation\n\ncache_lock = threading.Lock()\nglobal_cache = {}\n\n\ndef do_calculation(arg):\n    if arg in global_cache:\n        return global_cache[arg]\n\n    cache_lock.acquire()\n    if arg not in global_cache:\n        global_cache[arg] = _do_expensive_calculation(arg)\n    cache_lock.release()\n    return global_cache[arg]\n</code></pre> <p>Note that after acquiring the lock, we first check if the requested key has been filled by another thread, to prevent unnecessary calls to <code>_do_expensive_calculation</code> if another thread filled the cache while the thread currently holding the lock was blocked on acquiring the lock. Also note that <code>Lock.acquire</code> must be followed by a call to <code>Lock.release</code>, calling <code>Lock.acquire()</code> recursively on the same lock leads to deadlocks. Also, in general, it is possible to create a deadlock in any program with more than one lock. Care must be taken to ensure that operations done while the lock is held cannot lead to recursive calls or lead to a situation where a thread owning the lock is blocked on acquiring a difference mutex. You do not need to worry about deadlocking with the GIL in pure Python code, the interpreter will handle that for you.</p> <p>There is also threading.RLock, which provides a reentrant lock allowing threads to recursively acquire the same lock.</p>"},{"location":"porting/#dealing-with-thread-unsafe-objects","title":"Dealing with thread-unsafe objects","text":"<p>Mutability of objects is deeply embedded in the Python runtime and many tools freely assign to or mutate data stored in a python object.</p> <p>In the GIL-enabled build, in many cases, you can get away with mutating a shared object safely. This is true so long as whatever mutation you are attempting to do is fast enough that a thread switch is very unlikely to happen while you are doing work.</p> <p>In the free-threaded build there is no GIL to protect against mutation of state living on a Python object that is shared between threads. Just like when we used a lock to protect a global cache, we can also use a per-object lock to serialize access to state stored in a Python object. Consider the following class:</p> <pre><code>import time\nimport random\n\n\nclass RaceyCounter:\n    def __init__(self):\n        self.value = 0\n\n    def increment(self):\n        current_value = self.value\n        time.sleep(random.randint(0, 10) * 0.0001)\n        self.value = current_value + 1\n</code></pre> <p>Here we're simulating doing an in-place addition on an expensive function. A real example might have a method that looks something like this:</p> <pre><code>def increment(self):\n    self.value += do_some_expensive_calulation()\n</code></pre> <p>If we run this example in a thread pool, you'll see that the answer you get will vary randomly depending on the timing of the sleeps:</p> <pre><code>from concurrent.futures import ThreadPoolExecutor\n\ncounter = RaceyCounter()\n\n\ndef closure(counter):\n    counter.increment()\n\n\nwith ThreadPoolExecutor(max_workers=8) as tpe:\n    futures = [tpe.submit(closure, counter) for _ in range(1000)]\n    for f in futures:\n        f.result()\n\nprint(counter.value)\n</code></pre> <p>On both the free-threaded and GIL-enabled build, you will see the output of this script randomly vary.</p> <p>We can ensure the above script has determistic answers by adding a lock to our counter:</p> <pre><code>import threading\n\n\nclass SafeCounter:\n    def __init__(self):\n        self.value = 0\n        self.lock = threading.Lock()\n\n    def increment(self):\n        self.lock.acquire()\n        current_value = self.value\n        time.sleep(random.randint(0, 10) * 0.0001)\n        self.value = current_value + 1\n        self.lock.release()\n</code></pre> <p>If you replace <code>RaceyCounter</code> with <code>SafeCounter</code> in the script above, it will always output 1000.</p> <p>Of course this introduces a scaling bottleneck when <code>SafeCounter</code> instances are concurrently updated. It's possible to implement more optimized locking strategies, but doing so requires knowledge of the problem.</p>"},{"location":"resources/","title":"More Resources","text":"<p>Apart from this website, there's a wide list of resources on the free-threaded build and free-threading topics in general, including documentation, blog posts, conference talks, and others. We'll try to keep an up-to-date list here:</p> <ul> <li>Sam Gross's EuroPython talk</li> <li>PEP 703 design document</li> <li>C API Extension Support for Free Threading HOWTO on docs.python.org</li> <li><code>ft_utils</code> documentation</li> <li>PEP 703 initial discussion thread, as     well as the follow-up discussion thread</li> <li>PEP 703 acceptance announcement</li> <li>Quansight Labs blog post about work on free-threading</li> <li>Simon Willison's post about trying out free-threaded Python on macOS</li> <li>Codspeed's blog post about free-threading performance</li> <li>NVIDIA's blog post about threaded data loading</li> </ul> <p>There's also a lot of useful resources on CPython internals, that are not specific to the free-threaded build:</p> <ul> <li>CPython internal docs</li> <li>Dated tutorial on writing C extension modules</li> <li>Python behind the scenes series</li> <li>\u0141ukasz Langa's PyCon Thailand talk on the Python 3.13 release</li> <li>Anthony Shaw's PyCon US talk on free-threading and other parallelism concepts</li> </ul>"},{"location":"running-gil-disabled/","title":"Running Python with the GIL Disabled","text":"<p>Info</p> <p>Most of the content on this page is also covered in the Python 3.13 release notes.</p> <p>Note</p> <p>The free-threaded Python executable will always have a <code>python3.13t</code> alias (for Python 3.13); whether <code>python</code>, <code>python3</code> and/or <code>python3.13</code> point at the free-threaded executable or not will depend on the installation method (see the install guide for more details).</p> <p>For example, the Python 3.13 Windows installer from python.org installs the free-threaded binary as <code>python3.13t.exe</code> (with a \"t\" suffix to indicate it is \"t\"hreaded), whereas the standard GIL-enabled Python binary is simply named <code>python.exe</code> (as usual). If you cannot find the free-threaded binary, that means the free-threaded option was not selected during installation.</p> <p>You can verify if your build of CPython itself has the GIL disabled with the following incantation:</p> <pre><code>python -VV\n</code></pre> <p>If you are using Python 3.13b1 or newer, you should see a message like:</p> <pre><code>Python 3.13.1 experimental free-threading build (main, Dec 10 2024, 14:07:41) [Clang 16.0.0 (clang-1600.0.26.4)]\n</code></pre> <p>To verify whether the GIL is disabled at runtime or not, you can use this in your code:</p> <pre><code>import sys\n\nsys._is_gil_enabled()\n</code></pre> <p>This will be <code>True</code> on the free-threaded build when the GIL is re-enabled at runtime, but should be <code>False</code> before importing any packages. Note that <code>sys._is_gil_enabled()</code> is only available on Python 3.13 and newer, you will see an <code>AttributeError</code> on older Python versions.</p> <p>To force Python to keep the GIL disabled even after importing a module that does not support running without it, use the <code>PYTHON_GIL</code> environment variable or the <code>-X gil</code> command line option:</p> <pre><code># these are equivalent\nPYTHON_GIL=0 python\npython -Xgil=0\n</code></pre> <p>To check whether the Python interpreter you're using is a free-threaded build, irrespective of whether the GIL was re-enabled at runtime or not, you can use this within your code:</p> <pre><code>import sysconfig\n\nis_freethreaded = bool(sysconfig.get_config_var(\"Py_GIL_DISABLED\"))\n</code></pre>"},{"location":"testing/","title":"Validating thread safety with testing","text":"<p>Put priority on thread safety issues surfaced by real-world testing. Run the test suite for your project and fix any failures that occur only with the GIL disabled. Some issues may be due to changes in Python 3.13 that are not specific to the free-threaded build.</p> <p>If you are unable to run your package with the GIL disabled because of problems in extension modules or in dependencies, you can still test with the GIL enabled by setting the thread switch interval to a very small value (e.g. a microsecond or shorter). You can call <code>sys.setswitchiterval</code> before running multithreaded tests to force Python to release the GIL more often that the default configuration. This can expose thread safety issues that the GIL is masking.</p> <p>Unless your tests make heavy use of the <code>threading</code> module, you will likely not hit many issues, so also consider constructing multithreaded tests to expose bugs based on workflows you want to support. Issues found in these tests are the issues your users will most likely hit first.</p> <p>Multithreaded Python programs can exhibit race conditions which produce random results depending on the order of execution in a multithreaded context. This can happen even with the GIL providing locking, so long as the algorithm releases the GIL at some point, and many Python operations can lead to the GIL being released at some point. If your library was not designed with multithreading in mind, it is likely that some form of locking or synchronization is necessary to make mutable data structures defined by your library thread-safe. You should document the thread-safety guarantees of your library, both with and without the GIL.</p> <p>You should focus your efforts on analyzing the safety of shared use of mutable data structures or mutable global state. Decide whether it is supported and to what level it is supported to share mutable state between threads. It is a valid choice to leave it up to users to add synchronization, with the proviso that thread-unsafe data structures should be clearly documented as such.</p> <p>Generally global mutable state is not safe in the free-threaded build without some form of locking. Many projects use global mutable state (e.g. module-level or class-level state) for convenience with the assumption that the GIL provides locking on the state. That will most likely not be valid without some form of explicit locking on the free-threaded build. It is also likely that there are latent thread-safety issues related to use of global state even in the GIL-enabled build.</p> <p>Many test suites are implemented using global mutable state or assume that tests cannot run simultaneously. See the section below on global state in tests for more information about updating test suites to work with the free-threaded build and dealing with tests that become flaky when run in a thread pool.</p> <p>You can look at pytest-run-parallel as well as pytest-freethreaded, which both offer pytest plugins to enable running tests in an existing <code>pytest</code> test suite simultaneously in many threads, with the goal of validating thread safety. unittest-ft offers similar functionality for running <code>unittest</code>-based tests in parallel.</p> <p>These plugins are useful for discovering issues related to use of global state, but cannot discover issues from multithreaded use of data structures defined by your library.</p> <p>If you would like to create your own testing utilities, the <code>concurrent.futures.ThreadPoolExecutor</code> class is a lightweight way to create multithreaded tests where many threads repeatedly call a function simultaneously. You can also use the <code>threading</code> module directly for more complicated multithreaded test workflows. Adding a <code>threading.Barrier</code> before a line of code that you suspect will trigger a race condition is a good way to synchronize workers and increase the chances that an infrequent test failure will trigger.</p> <p>NumPy makes use of the following helper function to enable writing explicitly multithreaded tests, with a number of useful features to generically set up different testing scenarios:</p> <pre><code>from concurrent.futures import ThreadPoolExecutor\nimport threading\n\n\ndef run_threaded(\n    func,\n    num_threads=8,\n    pass_count=False,\n    pass_barrier=False,\n    outer_iterations=1,\n    prepare_args=None,\n):\n    \"\"\"Runs a function many times in parallel\"\"\"\n    for _ in range(outer_iterations):\n        with ThreadPoolExecutor(max_workers=num_threads) as tpe:\n            if prepare_args is None:\n                args = []\n            else:\n                args = prepare_args()\n            if pass_barrier:\n                barrier = threading.Barrier(num_threads)\n                args.append(barrier)\n            if pass_count:\n                all_args = [(func, i, *args) for i in range(num_threads)]\n            else:\n                all_args = [(func, *args) for i in range(num_threads)]\n            try:\n                futures = []\n                for arg in all_args:\n                    futures.append(tpe.submit(*arg))\n            finally:\n                if len(futures) &lt; num_threads and pass_barrier:\n                    barrier.abort()\n            for f in futures:\n                f.result()\n</code></pre> <p>Using this helper, you could write a multithreaded test using a shared list like this:</p> <pre><code>def test_parallel_append():\n    shared_list = []\n\n    def closure(i, b):\n        b.wait()\n        shared_list.append(i)\n\n    run_threaded(closure, num_threads=8, pass_barrier=True, pass_count=True)\n\n    assert sum(shared_list) == sum(range(8))\n</code></pre> <p>Generally multithreaded tests look something like the above: define a closure that operates on (possibly) shared data, spawn a thread pool that runs the closure in many threads, and assert something about the state of the world either inside the closure or after the thread pool finishes running. The assertion might be merely that a crash doesn't happen, in which case no explicit asserts are necessary.</p> <p>Tests that fail due to thread safety issues are inherently flaky. You should not be surprised to see tests that pass or fail randomly, or even fail a very small percentage of the time. When writing multithreaded tests your goal should be to maximize the chances of triggering a thread safety issue. You could pass <code>outer_iterations</code> to <code>run_threaded</code> to multiply the number of chances a thread triggers a thread safety issue in a single test.</p>"},{"location":"testing/#fixing-thread-unsafe-tests","title":"Fixing thread-unsafe tests.","text":"<p>Many existing tests are written using global state. This is not a problem if the test only runs once, but if you would like to use your tests to check for possible thread safety issues by running existing tests on many threads, you will likely need to update the tests to eliminate use of global state.</p> <p>Since tests using global state are inherently racey, this means that test failures associated with these tests are also inherently flakey. If you see tests failing intermittently, you should not discount that you are using global state in a test, or even inadvertently using global state in <code>pytest</code> itself.</p>"},{"location":"testing/#pytest-is-not-thread-safe","title":"<code>pytest</code> is not thread-safe","text":"<p>See the <code>pytest</code> docs for more information about this. While tests can manage their own threads, you should not assume that functionality provided by <code>pytest</code> is thread-safe.</p> <p>Functionality that is known not to be thread-safe includes:</p> <ul> <li><code>pytest.warns</code>,     it relies on <code>warnings.catch_warnings</code>, which is not thread-safe.</li> <li>The <code>tmp_path</code>     and <code>tmpdir</code>     fixtures, since they rely on the filesystem</li> <li>The <code>capsys</code>     fixture,     because of shared use of <code>sys.stdout</code> and <code>sys.stderr</code>.</li> <li>The <code>monkeypatch</code>     fixture.</li> </ul> <p>Note that the <code>pytest</code> maintainers have explicitly ruled out making <code>pytest</code> thread-safe, please do not open issues asking to fix thread safety issues in <code>pytest</code> itself.</p>"},{"location":"testing/#the-warnings-module-is-not-thread-safe","title":"The <code>warnings</code> module is not thread-safe","text":"<p>Many tests carefully ensure that warnings will be seen by the user in cases where the library author intends users to see them. These tests inevintably make use of the <code>warnings</code> module. As noted in the documentation for <code>warnings.catch_warnings</code>, the functionality provided by Python to track warnings is inherently thread-unsafe. This means tests that check for warnings should be marked as thread-unsafe and should be skipped when running tests on many threads simultaneously, since they will randomly pass or fail depending on thread timing.</p> <p>Hopefully in the future it will be possible for Python to write a scalable infrastucture for tracking warnings to fix this issue once and for all. See the CPython issue tracking this problem for more information.</p>"},{"location":"testing/#file-system-thread-safety","title":"File system thread safety","text":"<p>Many tests make use of the file system, either via a temporary file, or by simply directly writing to the folder running the test. If the filename used by the test is a constant or it is ever shared between instances of the test, the filesystem becomes shared global state, and the test will not be thread-safe.</p> <p>The easiest way to fix this is to use <code>tempfile</code>, which automatically handles generating file handles in a thread-safe manner. If for some reason this isn't practical, consider forcing the filenames used in tests to be unique, for example by appending a UUID to the filename.</p>"},{"location":"testing/#hypothesis-is-not-thread-safe","title":"Hypothesis is not thread-safe","text":"<p>The details of this are spelled out in the Hypothesis documentation. Similar to Pytest, it should be safe to spawn helper threads in a hypothesis test and pass data generated by hypothesis into those threads, so long as the use of helper threads does not change the order in which hypothesis generates test data or exhibits non-deterministic behavior. It is also not safe to interact with the Hypothesis API simultaneously from multiple threads.</p>"},{"location":"tracking/","title":"Compatibility Status Tracking","text":"<p>This page tracks the status of packages for which we're aware of active work on free-threaded support. It contains packages with extension modules, as well as build tools and packages that needed code specifically to support free-threading. Note that pure Python code works without changes by design, hence this page does not aim to track pure Python packages.</p> <p>We are updating this tracking table manually and including links to nightlies and project-specific issue links. There is also an automatically updated tracker that pulls in information for a wider range of packages, but only tracks whether or not they have wheels on PyPI.</p> <p>If there's a bug related to free-threading in a library you use, please open an issue on the corresponding issue tracker or post a comment on the corresponding free-threading support tracking issue (see table below). If an issue spans multiple projects or there's an ecosystem-wide point to discuss, please open an issue on this issue tracker.</p> <p>Tip</p> <p>It's early days for free-threaded support - bugs in CPython itself and in widely used libraries with extension modules are being fixed every week. It may be useful to use nightly wheels (when available) of packages like <code>cython</code> or <code>numpy</code>, even if a first release is available on PyPI. For example, you can install a NumPy nightly wheel by running:</p> <pre><code>pip install -i https://pypi.anaconda.org/scientific-python-nightly-wheels/simple numpy\n</code></pre> Project Upstream issue Tested in CI PyPI release First version with support Nightly wheels Nightly link Bazel (rules-python) <sup>1</sup> 0.39.0 bcrypt 4.3.0 bottleneck cffi cibuildwheel 2.19 CMake 3.30.0 ContourPy 1.3.0 cramjam cryptography Cython 3.1.0 hatch hypothesis JAX 0.5.1 joblib 1.4.2 jupyterlab kiwisolver 1.4.8 kornia-rs LibCST lz4 matplotlib 3.9.0 maturin 1.7.5 Meson 1.5.0 meson-python 0.16.0 ml-dtypes 0.5.1 mlir-python 20.1.0 multidict mypyc nanobind 2.2.0 Nuitka numexpr NumPy 2.1.0 nvImageCodec 0.4.0 ONNX orjson packaging 24.0 pandas 2.2.3 Pillow 11.0.0 pip 24.1 pydantic pydantic-core 2.29.0 PyArrow 18.0.0 pybind11 2.13 PyO3 <sup>2</sup> 0.23 PyObjC 11.0 Pythran PyTorch 2.6.0 PyWavelets 1.7.0 pywinpty 2.0.15 rpds-py 0.22.3 rust-numpy <sup>2</sup> 0.24.0 safetensors scikit-build-core 0.9.5 scikit-image 0.25.2 scikit-learn 1.6.0 SciPy 1.15.0 setuptools 69.5.0 Shapely 2.1.0 SWIG tox uv 0.4.24 wrapt 1.17.0 zstandard <ol> <li> <p>Release available in the Bazel Central Registry \u21a9</p> </li> <li> <p>Rust library released on crates.io \u21a9\u21a9</p> </li> </ol>"}]}